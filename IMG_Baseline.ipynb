{"cells":[{"outputs":"","execution_count":2,"source":"!pip install --upgrade pip -i https://pypi.tuna.tsinghua.edu.cn/simple","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"9B9A1418566945BF811E3A05884FEA56","scrolled":false}},{"outputs":"","execution_count":3,"source":"!pip install tensorflow==2.3.0 -i https://pypi.tuna.tsinghua.edu.cn/simple","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"B0B54F907B60461886F46AE6538ECA84","scrolled":false}},{"outputs":"","execution_count":4,"source":"!pip install torch===1.6.0 torchvision===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"E5EFB171EC264E489CB8DE85B0A03522","scrolled":false}},{"outputs":"","execution_count":5,"source":"! pip install opencv-python -i https://pypi.tuna.tsinghua.edu.cn/simple","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"DF48EB3680F8418099F6C67DEBC92355","scrolled":false}},{"metadata":{"id":"044D5936CA0F472BBBE604D108DCF04F","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":"","source":"! pip install numba -i https://pypi.tuna.tsinghua.edu.cn/simple","execution_count":6},{"metadata":{"id":"FE2AE5410F8F48BDAC71C33919E7FCF6","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"# DataGenerator"},{"metadata":{"id":"0AE1726133A6411C8BDAA75744AE52B1","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"from skimage.io import imread\nfrom skimage.transform import resize\nimport numpy as np\nfrom keras.utils import Sequence\nimport cv2\nimport glob\nimport os\nfrom tqdm import tqdm\n\nclass DataGenerator_train(Sequence):\n    \"\"\"\n    基于Sequence的自定义Keras数据生成器\n    \"\"\"\n    def __init__(self, filepath, batch_size=8, imgshape=(256, 472),\n                 n_channels=3, n_classes=13, label_dic={'others':0,'sunny':1,'cloudy':2},\n                 label_all={},shuffle=True):\n        \"\"\" 初始化方法\n        :param filepath :数据文件地址\n        :param batch_size: batch size\n        :param imgshape: 图像大小\n        :param n_channels: 图像通道\n        :param n_classes: 标签类别\n        :param shuffle: 每一个epoch后是否打乱数据\n        \"\"\"\n        self.filepath=filepath\n        # 文件地址list\n        self.pathlist=os.listdir(self.filepath)\n        self.batch_size = batch_size\n        self.imgshape = imgshape\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.label_dic = label_dic\n        self.label_all = label_all\n        # 每个epoch之后更新索引\n        self.on_epoch_end()\n\n    def __getitem__(self, index):\n        \"\"\"生成每一批次训练数据\n        :param index: 批次索引\n        :return: 训练图像和标签\n        \"\"\"\n        # 生成批次索引\n        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n        # 索引列表\n        batch_pathlist = [self.pathlist[k] for k in indexes]\n        # 生成数据\n        X = self._generate_X(batch_pathlist)\n        y = self._generate_y(batch_pathlist,self.label_all,self.label_dic)\n        return X, y\n\n    def __len__(self):\n        \"\"\"每个epoch下的批次数量,也就是每个epoch的iteration\n        \"\"\"\n        return int(np.floor(len(self.pathlist) / self.batch_size))\n\n    def _generate_X(self, batch_pathlist):\n        \"\"\"生成每一批次的图像\n        :param list_IDs_temp: 批次数据索引列表\n        :return: 一个批次的图像\n        \"\"\"\n        # 初始化\n        X = np.empty((self.batch_size, *self.imgshape, self.n_channels))\n        # 生成数据\n        for i, path in enumerate(batch_pathlist):\n            # 存储一个批次\n            X[i,] = self._load_image(self.filepath+path)\n        return X\n\n    def _generate_y(self, batch_pathlist,label_all,label_dic):\n        \"\"\"生成每一批次的标签\n        :param list_IDs_temp: 批次数据索引列表\n        :return: 一个批次的标签\n        \"\"\"\n        y = np.empty((self.batch_size, ), dtype=int)\n        # Generate data\n        for i, path in enumerate(batch_pathlist):\n            y[i] = label_dic[label_all[path]]\n        return y\n\n    def on_epoch_end(self):\n        \"\"\"每个epoch之后更新索引\n        \"\"\"\n        self.indexes = np.arange(len(self.pathlist))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def _load_image(self, image_path):\n        \"\"\"cv2读取图像\n        \"\"\"\n        # img = cv2.imread(image_path)\n        img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)\n        w, h, _ = img.shape\n        if w>h:\n            img = np.rot90(img)\n        img = cv2.resize(img, self.imgshape)\n        return img\n","execution_count":1},{"metadata":{"id":"C33A366D4E8043758273AE95A55DDE5C","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"from skimage.io import imread\nfrom skimage.transform import resize\nimport numpy as np\nfrom keras.utils import Sequence\nimport cv2\nimport glob\nimport os\nfrom tqdm import tqdm\n\nclass DataGenerator_test(Sequence):\n    \"\"\"\n    基于Sequence的自定义Keras数据生成器\n    \"\"\"\n    def __init__(self, filepath, batch_size=8, imgshape=(256, 472),\n                 n_channels=3, n_classes=13,shuffle=True):\n        \"\"\" 初始化方法\n        :param filepath :数据文件地址\n        :param batch_size: batch size\n        :param imgshape: 图像大小\n        :param n_channels: 图像通道\n        :param n_classes: 标签类别\n        :param shuffle: 每一个epoch后是否打乱数据\n        \"\"\"\n        self.filepath=filepath\n        # 文件地址list\n        self.pathlist=os.listdir(self.filepath)\n        self.batch_size = batch_size\n        self.imgshape = imgshape\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.test_ID_list = []\n        # 每个epoch之后更新索引\n        self.on_epoch_end()\n\n    def __getitem__(self, index):\n        \"\"\"生成每一批次训练数据\n        :param index: 批次索引\n        :return: 训练图像和标签\n        \"\"\"\n        # 生成批次索引\n        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n        # 索引列表\n        batch_pathlist = [self.pathlist[k] for k in indexes]\n        # 生成数据\n        X = self._generate_X(batch_pathlist)\n        self.test_ID_list.append(batch_pathlist)\n        return X\n\n    def __len__(self):\n        \"\"\"每个epoch下的批次数量,也就是每个epoch的iteration\n        \"\"\"\n        return int(np.floor(len(self.pathlist) / self.batch_size))\n\n    def _generate_X(self, batch_pathlist):\n        \"\"\"生成每一批次的图像\n        :param list_IDs_temp: 批次数据索引列表\n        :return: 一个批次的图像\n        \"\"\"\n        # 初始化\n        X = np.empty((self.batch_size, *self.imgshape, self.n_channels))\n        # 生成数据\n        for i, path in enumerate(batch_pathlist):\n            # 存储一个批次\n            X[i,] = self._load_image(self.filepath+path)\n        return X\n\n    def on_epoch_end(self):\n        \"\"\"每个epoch之后更新索引\n        \"\"\"\n        self.indexes = np.arange(len(self.pathlist))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def _load_image(self, image_path):\n        \"\"\"cv2读取图像\n        \"\"\"\n        # img = cv2.imread(image_path)\n        img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)\n        w, h, _ = img.shape\n        if w>h:\n            img = np.rot90(img)\n        img = cv2.resize(img, self.imgshape)\n        return img\n","execution_count":2},{"metadata":{"id":"C91EA7F4A3524FF9806B27D0E6EAC938","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"label load done\ntraining_generator build done\n","name":"stdout"}],"source":"with open('/home/kesci/data/competition/train_set/Part1.json', encoding=\"utf-8\") as f:\n    label_all = json.load(f)\nprint('label load done')\n# Parameters\nparams = {'batch_size': 1,\n        'n_classes': 3,\n        'n_channels': 3,\n        'shuffle': True,\n        'label_dic':{'others':0,'sunny':1,'cloudy':2},\n        'label_all':label_all,\n        'imgshape':(256,256)}\ntrain_filepath=r'/home/kesci/data/competition/train_set/Part1/'\n# Generators\ntraining_generator = DataGenerator_train(train_filepath, **params)\nprint('training_generator build done')\n# for x,y in training_generator:\n#     print(y)","execution_count":3},{"metadata":{"id":"EB555623B5B94970985173256BB49BEB","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"testing_generator build done\n","name":"stdout"}],"source":"# Parameters\nparams = {'batch_size': 1,\n        'n_classes': 3,\n        'n_channels': 3,\n        'shuffle': True,\n        'imgshape':(256,256)}\ntest_filepath=r'/home/kesci/data/competition/train_set/Part1/'\n# Generators\ntesting_generator = DataGenerator_test(test_filepath, **params)\nprint('testing_generator build done')\n# for x,ID in testing_generator:\n#     print(ID)","execution_count":4},{"metadata":{"id":"109E591534B3482C932B556A4EE54C65","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"# CNN BaseLine"},{"metadata":{"id":"3672B01FDF5D4FB180DDF3B832683F37","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":"","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models\n\nfrom tensorflow.keras.callbacks import EarlyStopping","execution_count":9},{"metadata":{"id":"0A7C8F2F79A143419FD0FE28D4BF19BC","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":"","source":"model = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(3, activation='softmax'))","execution_count":10},{"metadata":{"id":"BDF1FDE92C794345874306EC5921134C","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":"","source":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","execution_count":11},{"metadata":{"id":"47F8CA0173104FED8ED900478C72F20D","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":true},"cell_type":"code","outputs":"","source":"earlystop_callback = EarlyStopping(monitor='accuracy',\n                                    min_delta=0.00001,\n                                    patience=20,\n                                    verbose=1,\n                                    mode='max',\n                                    baseline=None,\n                                    restore_best_weights=True,)\n\nmodel.fit_generator(generator=training_generator,\n                # validation_split=0.3, \n                epochs=5,\n                callbacks=[earlystop_callback])","execution_count":13},{"metadata":{"id":"DA8A441472594E1283518E06C073E03C","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":"","source":"model.predict_generator(generator=testing_generator,verbose=1)\nsub_ID = testing_generator.test_ID_list","execution_count":33},{"metadata":{"id":"4201340499D24A428DB432FE91173FDA","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"# EfficientNet"},{"metadata":{"id":"79964D633EEC4F128F03AF0F1CC32949","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models\n\nfrom tensorflow.keras.callbacks import EarlyStopping","execution_count":null},{"metadata":{"id":"548F0AD22EAC492B87A69A8358175DD0","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"import tensorflow as tf\nimport math\n\nNUM_CLASSES = 3\n\ndef swish(x):\n    return x * tf.nn.sigmoid(x)\n\n\ndef round_filters(filters, multiplier):\n    depth_divisor = 8\n    min_depth = None\n    min_depth = min_depth or depth_divisor\n    filters = filters * multiplier\n    new_filters = max(min_depth, int(filters + depth_divisor / 2) // depth_divisor * depth_divisor)\n    if new_filters < 0.9 * filters:\n        new_filters += depth_divisor\n    return int(new_filters)\n\n\ndef round_repeats(repeats, multiplier):\n    if not multiplier:\n        return repeats\n    return int(math.ceil(multiplier * repeats))\n\n\nclass SEBlock(tf.keras.layers.Layer):\n    def __init__(self, input_channels, ratio=0.25):\n        super(SEBlock, self).__init__()\n        self.num_reduced_filters = max(1, int(input_channels * ratio))\n        self.pool = tf.keras.layers.GlobalAveragePooling2D()\n        self.reduce_conv = tf.keras.layers.Conv2D(filters=self.num_reduced_filters,\n                                                  kernel_size=(1, 1),\n                                                  strides=1,\n                                                  padding=\"same\")\n        self.expand_conv = tf.keras.layers.Conv2D(filters=input_channels,\n                                                  kernel_size=(1, 1),\n                                                  strides=1,\n                                                  padding=\"same\")\n\n    def call(self, inputs, **kwargs):\n        branch = self.pool(inputs)\n        branch = tf.expand_dims(input=branch, axis=1)\n        branch = tf.expand_dims(input=branch, axis=1)\n        branch = self.reduce_conv(branch)\n        branch = swish(branch)\n        branch = self.expand_conv(branch)\n        branch = tf.nn.sigmoid(branch)\n        output = inputs * branch\n        return output\n\n\nclass MBConv(tf.keras.layers.Layer):\n    def __init__(self, in_channels, out_channels, expansion_factor, stride, k, drop_connect_rate):\n        super(MBConv, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.stride = stride\n        self.drop_connect_rate = drop_connect_rate\n        self.conv1 = tf.keras.layers.Conv2D(filters=in_channels * expansion_factor,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=\"same\")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.dwconv = tf.keras.layers.DepthwiseConv2D(kernel_size=(k, k),\n                                                      strides=stride,\n                                                      padding=\"same\")\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.se = SEBlock(input_channels=in_channels * expansion_factor)\n        self.conv2 = tf.keras.layers.Conv2D(filters=out_channels,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=\"same\")\n        self.bn3 = tf.keras.layers.BatchNormalization()\n        self.dropout = tf.keras.layers.Dropout(rate=drop_connect_rate)\n\n    def call(self, inputs, training=None, **kwargs):\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = swish(x)\n        x = self.dwconv(x)\n        x = self.bn2(x, training=training)\n        x = self.se(x)\n        x = swish(x)\n        x = self.conv2(x)\n        x = self.bn3(x, training=training)\n        if self.stride == 1 and self.in_channels == self.out_channels:\n            if self.drop_connect_rate:\n                x = self.dropout(x, training=training)\n            x = tf.keras.layers.add([x, inputs])\n        return x\n\n\ndef build_mbconv_block(in_channels, out_channels, layers, stride, expansion_factor, k, drop_connect_rate):\n    block = tf.keras.Sequential()\n    for i in range(layers):\n        if i == 0:\n            block.add(MBConv(in_channels=in_channels,\n                             out_channels=out_channels,\n                             expansion_factor=expansion_factor,\n                             stride=stride,\n                             k=k,\n                             drop_connect_rate=drop_connect_rate))\n        else:\n            block.add(MBConv(in_channels=out_channels,\n                             out_channels=out_channels,\n                             expansion_factor=expansion_factor,\n                             stride=1,\n                             k=k,\n                             drop_connect_rate=drop_connect_rate))\n    return block\n\n\nclass EfficientNet(tf.keras.Model):\n    def __init__(self, width_coefficient, depth_coefficient, dropout_rate, drop_connect_rate=0.2):\n        super(EfficientNet, self).__init__()\n\n        self.conv1 = tf.keras.layers.Conv2D(filters=round_filters(32, width_coefficient),\n                                            kernel_size=(3, 3),\n                                            strides=2,\n                                            padding=\"same\")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.block1 = build_mbconv_block(in_channels=round_filters(32, width_coefficient),\n                                         out_channels=round_filters(16, width_coefficient),\n                                         layers=round_repeats(1, depth_coefficient),\n                                         stride=1,\n                                         expansion_factor=1, k=3, drop_connect_rate=drop_connect_rate)\n        self.block2 = build_mbconv_block(in_channels=round_filters(16, width_coefficient),\n                                         out_channels=round_filters(24, width_coefficient),\n                                         layers=round_repeats(2, depth_coefficient),\n                                         stride=2,\n                                         expansion_factor=6, k=3, drop_connect_rate=drop_connect_rate)\n        self.block3 = build_mbconv_block(in_channels=round_filters(24, width_coefficient),\n                                         out_channels=round_filters(40, width_coefficient),\n                                         layers=round_repeats(2, depth_coefficient),\n                                         stride=2,\n                                         expansion_factor=6, k=5, drop_connect_rate=drop_connect_rate)\n        self.block4 = build_mbconv_block(in_channels=round_filters(40, width_coefficient),\n                                         out_channels=round_filters(80, width_coefficient),\n                                         layers=round_repeats(3, depth_coefficient),\n                                         stride=2,\n                                         expansion_factor=6, k=3, drop_connect_rate=drop_connect_rate)\n        self.block5 = build_mbconv_block(in_channels=round_filters(80, width_coefficient),\n                                         out_channels=round_filters(112, width_coefficient),\n                                         layers=round_repeats(3, depth_coefficient),\n                                         stride=1,\n                                         expansion_factor=6, k=5, drop_connect_rate=drop_connect_rate)\n        self.block6 = build_mbconv_block(in_channels=round_filters(112, width_coefficient),\n                                         out_channels=round_filters(192, width_coefficient),\n                                         layers=round_repeats(4, depth_coefficient),\n                                         stride=2,\n                                         expansion_factor=6, k=5, drop_connect_rate=drop_connect_rate)\n        self.block7 = build_mbconv_block(in_channels=round_filters(192, width_coefficient),\n                                         out_channels=round_filters(320, width_coefficient),\n                                         layers=round_repeats(1, depth_coefficient),\n                                         stride=1,\n                                         expansion_factor=6, k=3, drop_connect_rate=drop_connect_rate)\n\n        self.conv2 = tf.keras.layers.Conv2D(filters=round_filters(1280, width_coefficient),\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=\"same\")\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.pool = tf.keras.layers.GlobalAveragePooling2D()\n        self.dropout = tf.keras.layers.Dropout(rate=dropout_rate)\n        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES,\n                                        activation=tf.keras.activations.softmax)\n\n    def call(self, inputs, training=None, mask=None):\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = swish(x)\n\n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        x = self.block4(x)\n        x = self.block5(x)\n        x = self.block6(x)\n        x = self.block7(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n        x = swish(x)\n        x = self.pool(x)\n        x = self.dropout(x, training=training)\n        x = self.fc(x)\n\n        return x\n\n\ndef get_efficient_net(width_coefficient, depth_coefficient, resolution, dropout_rate):\n    net = EfficientNet(width_coefficient=width_coefficient,\n                       depth_coefficient=depth_coefficient,\n                       dropout_rate=dropout_rate)\n    net.build(input_shape=(None, resolution, resolution, 3))\n    net.summary()\n\n    return net\n\n\ndef efficient_net_b0():\n    return get_efficient_net(1.0, 1.0, 224, 0.2)\n\n\ndef efficient_net_b1():\n    return get_efficient_net(1.0, 1.1, 240, 0.2)\n\n\ndef efficient_net_b2():\n    return get_efficient_net(1.1, 1.2, 260, 0.3)\n\n\ndef efficient_net_b3():\n    return get_efficient_net(1.2, 1.4, 300, 0.3)\n\n\ndef efficient_net_b4():\n    return get_efficient_net(1.4, 1.8, 380, 0.4)\n\n\ndef efficient_net_b5():\n    return get_efficient_net(1.6, 2.2, 456, 0.4)\n\n\ndef efficient_net_b6():\n    return get_efficient_net(1.8, 2.6, 528, 0.5)\n\n\ndef efficient_net_b7():\n    return get_efficient_net(2.0, 3.1, 600, 0.5)","execution_count":5},{"metadata":{"id":"BD8DE85725E444F78966FB58AA5A231F","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Model: \"efficient_net\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              multiple                  2688      \n_________________________________________________________________\nbatch_normalization (BatchNo multiple                  384       \n_________________________________________________________________\nsequential (Sequential)      (None, 2, 2, 48)          34560     \n_________________________________________________________________\nsequential_1 (Sequential)    (None, 1, 1, 72)          905364    \n_________________________________________________________________\nsequential_2 (Sequential)    (None, 1, 1, 120)         2486016   \n_________________________________________________________________\nsequential_3 (Sequential)    (None, 1, 1, 240)         14601060  \n_________________________________________________________________\nsequential_4 (Sequential)    (None, 1, 1, 336)         29613240  \n_________________________________________________________________\nsequential_5 (Sequential)    (None, 1, 1, 576)         114842520 \n_________________________________________________________________\nsequential_6 (Sequential)    (None, 1, 1, 960)         66894048  \n_________________________________________________________________\nconv2d_193 (Conv2D)          multiple                  3690240   \n_________________________________________________________________\nbatch_normalization_145 (Bat multiple                  15360     \n_________________________________________________________________\nglobal_average_pooling2d_48  multiple                  0         \n_________________________________________________________________\ndropout_48 (Dropout)         multiple                  0         \n_________________________________________________________________\ndense (Dense)                multiple                  11523     \n=================================================================\nTotal params: 233,097,003\nTrainable params: 232,690,635\nNon-trainable params: 406,368\n_________________________________________________________________\n","name":"stdout"}],"source":"width_coefficient = 3\ndepth_coefficient = 3\nresolution = 3\ndropout_rate = 0.5\nmodel = get_efficient_net(width_coefficient, depth_coefficient, resolution, dropout_rate)","execution_count":6},{"metadata":{"id":"4917BB271F894A388EE1E79103E146A3","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","execution_count":7},{"metadata":{"id":"437899F775F546B0A827C30F68669B3C","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'EarlyStopping' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-2d5aa942cd7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m earlystop_callback = EarlyStopping(monitor='accuracy',\n\u001b[0m\u001b[1;32m      2\u001b[0m                                     \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                     \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                     \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"]}],"source":"earlystop_callback = EarlyStopping(monitor='accuracy',\n                                    min_delta=0.00001,\n                                    patience=20,\n                                    verbose=1,\n                                    mode='max',\n                                    baseline=None,\n                                    restore_best_weights=True,)\n\nmodel.fit_generator(generator=training_generator,\n                # validation_split=0.3, \n                epochs=5,\n                callbacks=[earlystop_callback])","execution_count":8},{"metadata":{"id":"C723A6CBB4A74C98BBF6CA02D30EAD94","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"model.predict_generator(generator=testing_generator,verbose=1)\nsub_ID = testing_generator.test_ID_list","execution_count":null},{"metadata":{"id":"508DCD8199094A1A8FEC778783D837B8","notebookId":"5f89ec30bfe3ac0015e7881c","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"","execution_count":null}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}